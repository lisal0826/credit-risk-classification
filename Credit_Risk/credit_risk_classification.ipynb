{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Read the `lending_data.csv` data from the `Resources` folder into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training features: (62028, 7)\n",
      "Shape of testing features: (15508, 7)\n",
      "Shape of training labels: (62028,)\n",
      "Shape of testing labels: (15508,)\n"
     ]
    }
   ],
   "source": [
    "# Read the lending_data.csv data from the Resources folder into a Pandas DataFrame\n",
    "data = pd.read_csv(\"C:/Users/lisal/Documents/credit-risk-classification/Credit_Risk/Resources/lending_data.csv\")\n",
    "\n",
    "# Create the labels set (y) from the “loan_status” column\n",
    "y = data[\"loan_status\"]\n",
    "\n",
    "# Create the features (X) DataFrame from the remaining columns\n",
    "X = data.drop(\"loan_status\", axis=1)\n",
    "\n",
    "# Split the data into training and testing datasets by using train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Printing the shape of the training and testing datasets\n",
    "print(\"Shape of training features:\", X_train.shape)\n",
    "print(\"Shape of testing features:\", X_test.shape)\n",
    "print(\"Shape of training labels:\", y_train.shape)\n",
    "print(\"Shape of testing labels:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create the labels set (`y`)  from the “loan_status” column, and then create the features (`X`) DataFrame from the remaining columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of labels (y): (77536,)\n",
      "Shape of features (X): (77536, 7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the lending_data.csv data from the Resources folder into a Pandas DataFrame\n",
    "data = pd.read_csv(\"C:/Users/lisal/Documents/credit-risk-classification/Credit_Risk/Resources/lending_data.csv\")\n",
    "\n",
    "# Separate the y variable, the labels\n",
    "y = data[\"loan_status\"]\n",
    "\n",
    "# Separate the X variable, the features\n",
    "X = data.drop(\"loan_status\", axis=1)\n",
    "\n",
    "# Printing the shapes of the labels and features datasets\n",
    "print(\"Shape of labels (y):\", y.shape)\n",
    "print(\"Shape of features (X):\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "77531    1\n",
      "77532    1\n",
      "77533    1\n",
      "77534    1\n",
      "77535    1\n",
      "Name: loan_status, Length: 77536, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Review the y variable Series\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       loan_size  interest_rate  borrower_income  debt_to_income  \\\n",
      "0        10700.0          7.672            52800        0.431818   \n",
      "1         8400.0          6.692            43600        0.311927   \n",
      "2         9000.0          6.963            46100        0.349241   \n",
      "3        10700.0          7.664            52700        0.430740   \n",
      "4        10800.0          7.698            53000        0.433962   \n",
      "...          ...            ...              ...             ...   \n",
      "77531    19100.0         11.261            86600        0.653580   \n",
      "77532    17700.0         10.662            80900        0.629172   \n",
      "77533    17600.0         10.595            80300        0.626401   \n",
      "77534    16300.0         10.068            75300        0.601594   \n",
      "77535    15600.0          9.742            72300        0.585062   \n",
      "\n",
      "       num_of_accounts  derogatory_marks  total_debt  \n",
      "0                    5                 1       22800  \n",
      "1                    3                 0       13600  \n",
      "2                    3                 0       16100  \n",
      "3                    5                 1       22700  \n",
      "4                    5                 1       23000  \n",
      "...                ...               ...         ...  \n",
      "77531               12                 2       56600  \n",
      "77532               11                 2       50900  \n",
      "77533               11                 2       50300  \n",
      "77534               10                 2       45300  \n",
      "77535                9                 2       42300  \n",
      "\n",
      "[77536 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Review the X variable DataFrame\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Check the balance of the labels variable (`y`) by using the `value_counts` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_status\n",
      "0    75036\n",
      "1     2500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the balance of our target values\n",
    "print(y.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Split the data into training and testing datasets by using `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data using train_test_split\n",
    "# Assign a random_state of 1 to the function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Logistic Regression Model with the Original Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 1: Fit a logistic regression model by using the training data (`X_train` and `y_train`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate the Logistic Regression model\n",
    "# Assign a random_state parameter of 1 to the model\n",
    "logistic_regression_model = LogisticRegression(random_state=1)\n",
    "\n",
    "# Fit the model using training data\n",
    "logistic_regression_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Save the predictions on the testing data labels by using the testing feature data (`X_test`) and the fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction using the testing data\n",
    "y_pred = logistic_regression_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Evaluate the model’s performance by doing the following:\n",
    "\n",
    "* Calculate the accuracy score of the model.\n",
    "\n",
    "* Generate a confusion matrix.\n",
    "\n",
    "* Print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy Score: 0.9521352751368186\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Calculate the balanced accuracy score\n",
    "balanced_acc_score = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the balanced accuracy score of the model\n",
    "print(\"Balanced Accuracy Score:\", balanced_acc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[14926    75]\n",
      " [   46   461]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Generate a confusion matrix for the model\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     15001\n",
      "           1       0.86      0.91      0.88       507\n",
      "\n",
      "    accuracy                           0.99     15508\n",
      "   macro avg       0.93      0.95      0.94     15508\n",
      "weighted avg       0.99      0.99      0.99     15508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Print the classification report for the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Answer the following question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How well does the logistic regression model predict both the `0` (healthy loan) and `1` (high-risk loan) labels?\n",
    "\n",
    "**Answer:** Balanced Accuracy Score: The balanced accuracy score is approximately 0.952, which indicates that the logistic regression model performs well in predicting both the \"0\" (healthy loan) and \"1\" (high-risk loan) labels. A balanced accuracy score close to 1 indicates good performance.\n",
    "\n",
    "Confusion Matrix: The confusion matrix shows that out of 15001 healthy loans (label \"0\"), 14926 were correctly classified as healthy, and 75 were incorrectly classified as high-risk. Similarly, out of 507 high-risk loans (label \"1\"), 461 were correctly classified as high-risk, and 46 were incorrectly classified as healthy.\n",
    "\n",
    "Classification Report: The precision, recall, and F1-score for both classes (\"0\" and \"1\") are relatively high, indicating good performance of the model in predicting both classes. Specifically, for label \"1\" (high-risk loan), the precision is 0.86, recall is 0.91, and F1-score is 0.88, suggesting that the model performs well in identifying high-risk loans.\n",
    "\n",
    "Overall Assessment: The logistic regression model appears to perform well in predicting both healthy and high-risk loans. It demonstrates high precision, recall, and F1-score for both classes, as indicated by the classification report. Additionally, the balanced accuracy score further supports the model's overall effectiveness in classification.\n",
    "\n",
    "In conclusion, the logistic regression model demonstrates strong predictive capabilities for both healthy and high-risk loans based on the provided evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict a Logistic Regression Model with Resampled Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Use the `RandomOverSampler` module from the imbalanced-learn library to resample the data. Be sure to confirm that the labels have an equal number of data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Replace the import statement for RandomOverSampler with the code for RandomOverSampler\n",
    "# Create a class that replicates the functionality of RandomOverSampler without importing it directly\n",
    "class RandomOverSampler:\n",
    "    def __init__(self, random_state=None):\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit_resample(self, X, y):\n",
    "        # Implement random oversampling functionality here\n",
    "        return X_resampled, y_resampled  \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class RandomOverSampler:\n",
    "    def __init__(self, random_state=None):\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit_resample(self, X, y):\n",
    "        # Setting the random seed for reproducibility if random_state is provided\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "\n",
    "        # Identifying the majority and minority classes\n",
    "        unique_classes, counts = np.unique(y, return_counts=True)\n",
    "        majority_class = unique_classes[np.argmax(counts)]\n",
    "        minority_class = unique_classes[np.argmin(counts)]\n",
    "\n",
    "        # Finding the indices of majority and minority samples\n",
    "        majority_indices = np.where(y == majority_class)[0]\n",
    "        minority_indices = np.where(y == minority_class)[0]\n",
    "\n",
    "        # Calculating how many minority samples to generate\n",
    "        samples_to_generate = counts[np.argmax(counts)] - counts[np.argmin(counts)]\n",
    "\n",
    "        # Randomly duplicating minority samples\n",
    "        random_indices = np.random.choice(minority_indices, samples_to_generate, replace=True)\n",
    "        X_minority_upsampled = X[random_indices]\n",
    "        y_minority_upsampled = y[random_indices]\n",
    "\n",
    "        # Combining the upsampled minority class with the original majority class\n",
    "        X_resampled = np.vstack((X[majority_indices], X_minority_upsampled))\n",
    "        y_resampled = np.concatenate((y[majority_indices], y_minority_upsampled))\n",
    "\n",
    "        return X_resampled, y_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class RandomOverSampler:\n",
    "    def __init__(self, random_state=None):\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit_resample(self, X, y):\n",
    "        # Setting the random seed for reproducibility if random_state is provided\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "\n",
    "        # Identifying the majority and minority classes\n",
    "        unique_classes, counts = np.unique(y, return_counts=True)\n",
    "        majority_class = unique_classes[np.argmax(counts)]\n",
    "        minority_class = unique_classes[np.argmin(counts)]\n",
    "\n",
    "        # Finding the indices of majority and minority samples\n",
    "        majority_indices = np.where(y == majority_class)[0]\n",
    "        minority_indices = np.where(y == minority_class)[0]\n",
    "\n",
    "        # Calculating how many minority samples to generate\n",
    "        samples_to_generate = counts[np.argmax(counts)] - counts[np.argmin(counts)]\n",
    "\n",
    "        # Randomly duplicating minority samples\n",
    "        random_indices = np.random.choice(minority_indices, samples_to_generate, replace=True)\n",
    "        X_minority_upsampled = X.iloc[random_indices]  # Corrected to use .iloc\n",
    "        y_minority_upsampled = y.iloc[random_indices]  # Corrected to use .iloc\n",
    "\n",
    "        # Combining the upsampled minority class with the original majority class\n",
    "        X_resampled = np.vstack((X.iloc[majority_indices].values, X_minority_upsampled.values))\n",
    "        y_resampled = np.concatenate((y.iloc[majority_indices].values, y_minority_upsampled.values))\n",
    "\n",
    "        return X_resampled, y_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the RandomOverSampler with a random state\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "\n",
    "# Resample the training data\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy Score: 0.9941749445500477\n",
      "Confusion Matrix:\n",
      "[[14915    86]\n",
      " [    3   504]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     15001\n",
      "           1       0.85      0.99      0.92       507\n",
      "\n",
      "    accuracy                           0.99     15508\n",
      "   macro avg       0.93      0.99      0.96     15508\n",
      "weighted avg       1.00      0.99      0.99     15508\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate the Logistic Regression model with a random state of 1\n",
    "logistic_regression_model = LogisticRegression(random_state=1, max_iter=1000)  # max_iter may be set to a higher value if needed\n",
    "\n",
    "# Fit the model using the resampled training data\n",
    "logistic_regression_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make a prediction using the testing data\n",
    "y_pred = logistic_regression_model.predict(X_test)\n",
    "\n",
    "# (Optional) You might want to evaluate the model performance as well\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Calculate the balanced accuracy score\n",
    "balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Generate a confusion matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Generate a classification report\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Balanced Accuracy Score:\", balanced_accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Evaluate the model’s performance by doing the following:\n",
    "\n",
    "* Calculate the accuracy score of the model.\n",
    "\n",
    "* Generate a confusion matrix.\n",
    "\n",
    "* Print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy Score: 0.9941749445500477\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Calculate the balanced accuracy score of the model\n",
    "balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the balanced accuracy score of the model\n",
    "print(\"Balanced Accuracy Score:\", balanced_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[14915    86]\n",
      " [    3   504]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Generate a confusion matrix for the model\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     15001\n",
      "           1       0.85      0.99      0.92       507\n",
      "\n",
      "    accuracy                           0.99     15508\n",
      "   macro avg       0.93      0.99      0.96     15508\n",
      "weighted avg       1.00      0.99      0.99     15508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate and print the classification report for the model\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Answer the following question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How well does the logistic regression model, fit with oversampled data, predict both the `0` (healthy loan) and `1` (high-risk loan) labels?\n",
    "\n",
    "**Answer:** The logistic regression model, when fit with oversampled data, demonstrates excellent performance in predicting both the 0 (healthy loan) and 1 (high-risk loan) labels, as indicated by the metrics provided:\n",
    "\n",
    "Balanced Accuracy Score: The model achieves a very high balanced accuracy score of approximately 0.994, indicating that it has a great overall accuracy in predicting both classes. This metric is especially important in the context of imbalanced datasets because it accounts for the balance between sensitivity and specificity.\n",
    "\n",
    "Confusion Matrix: The confusion matrix reveals that out of 15,508 predictions,\n",
    "\n",
    "For the 0 label (healthy loan), the model correctly predicts 14,915 as healthy loans while misclassifying 86 as high-risk loans. This indicates a very high true negative rate, showing the model's effectiveness in identifying healthy loans.\n",
    "For the 1 label (high-risk loan), the model correctly identifies 504 as high-risk loans and only fails to recognize 3 as such. This demonstrates an exceptionally high true positive rate, indicating the model's proficiency in detecting high-risk loans despite their minority presence in the dataset.\n",
    "Classification Report:\n",
    "\n",
    "The precision for healthy loans (0) is essentially perfect (1.00), indicating that almost all loans predicted as healthy are indeed healthy. For high-risk loans (1), the precision is 0.85, meaning that 85% of loans predicted as high-risk are actually high-risk, which is still quite good.\n",
    "The recall for healthy loans is 0.99, showing the model's capability to identify the vast majority of healthy loans correctly. The recall for high-risk loans is near perfect at 0.99, indicating the model's strong ability to detect almost all high-risk loans.\n",
    "The f1-score, which balances precision and recall, is outstanding for both classes, with healthy loans at 1.00 and high-risk loans at 0.92. This suggests a very efficient balance between precision and recall for both classes.\n",
    "In summary, the logistic regression model fitted with oversampled data predicts both 0 (healthy loan) and 1 (high-risk loan) labels with high accuracy, precision, recall, and f1-scores. It is particularly adept at identifying high-risk loans, a critical capability for risk management in lending. The slight trade-off in precision for high-risk loans (with a precision of 0.85) is more than compensated for by the model's high recall in this class, making it very valuable for identifying potentially risky loans that require further scrutiny."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
